---
title: "Treelet Transform: Identifing clusters of ICD-9 Diagnoses in a Boston Trauma Center"
subtitle: "Data Analysis: Treelet & GLM Fitting"
author: "Dominic DiSanto\n Master's Thesis"
date: "Updated 9/20/2020"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_depth: '3'
    code_folding: show
---

## Preparation


## Libraries
```{r, message=F, warning=FALSE}
library(magrittr) # Ceci n'est pas une %>%, loaded via dplyr also but liked to include for transparency 
library(dplyr) # General data management, cleaning (admittedly I switch between Base R and tidyverse as I code, somewhat stream-of-consciousness ly)
library(ggplot2) # Visualization
library(tidyr) # pivot functions for transposing data to/from long and wide
library(icd) # used in validity check of diagnoses codes
library(lubridate) # used in evaluating dates, most notably in date of death 
library(lares) # corr_cross function used to identify the top correlations within a data frame/design matrix
library(corrplot) # used for visualizing correlation matrices
library(here) # Used for data-calls/ease of file path storage usage 
library(treelet) # Used for treelet analysis 
library(ggdendro) # Used for dendrogram visualization of Treelet analysis
library(gghighlight) # Used in cross-validation visualizations
library(MASS) # Used for glm.nb negative binomial regression function 
require(stringr) # Some regex matching for filtering in the visualiation of p-values & coefficients from GLM's 

select <- dplyr::select # Masking the MASS select function, somethign to do with ridge regression I think, in favor of dplyr's `select()` function for wrangling

`%nin%` <- Negate(`%in%`) # Creating the inverse function of %in%, simpler than working with the !(...) negating logic syntax and saves me the extra parenthetical blocks
```


## File Path & Import

Loading data via `here` package 

```{r}
here()

cohort_full <-  read.csv(here("Data", "cohort_full.csv"))
colnames(cohort_full) <- cohort_full %>% colnames() %>% gsub(pattern = "X", "", x = .)
# cohort_full %>% head()

diagnosis_labs <- read.csv(here("Data", "Raw", "D_ICD_DIAGNOSES.csv"))
```



## Treelet Cross-Validation Function

Defining the function that fits the treelet, and retains the characteristics of:  
- The "best K-basis" or the optimal L|K parameter for each K   
- The retained K features for each given K   
- All p-1 basis matrices from the fit treelet   


```{r}
treelet_process <- function(x_mat, cov_mat){

  tt_results <- tt_results <- treelet::Run_JTree(cov_mat, nrow(cov_mat)-1, 1:nrow(cov_mat)-1) # Running the `treelet` package's implementation and retaining all (1) to (p-1) results
  energy <- list() # empty list to store energy scores

      for(L in 1:length(tt_results$basis)) { # repeating this for all basis matrices identified in the treelet above
        
        basisk <- tt_results$basis[[L]] # storing the specific basis
        w_x <- t(basisk) %*% t(x_mat) # applying the basis matrix to the original input matri of diagnosis codes 
    
          num_vec <- rowSums(abs(w_x)^2) # numerator vector -> calculation of the p-1 values for the numerator of the energy score calculation
          den_vec <- x_mat^2 %>% colSums() # similar to the above line but the denominator calculation, column summed over all n observations
              names(num_vec) <- NULL # removing dimension names o fmatrix
              names(den_vec) <- NULL
    
        energy[[L]] <- matrix(c(1:ncol(x_mat), num_vec / den_vec), ncol=2, dimnames = list(NULL, c("W_i", "Energy"))) # generating energy scores
    }

  # Creating blank objects  
    optimal_L <- matrix(c(1:length(energy), rep(NA, length(energy))), nrow=length(energy), dimnames = list(NULL, c("K", "Optimal L"))) # empty list set
    retained_fts <- rep(list(rep(list(rep(NA, length(energy))), length(energy))), length(energy)) # empty list set

  # Reordering the energy matrices in descending order of normed energy score
    energy_ordered <- lapply(1:length(energy), function(L) energy[[L]][energy[[L]][,2] %>% order(decreasing = T),]) # sorting all p-1 energy vectors in descending order

  # Identifying optimal L
    optimal_L <- matrix(c(1:length(energy_ordered), # identifying the basis matrix with the highest energy summation for every given K
                      sapply(1:length(energy_ordered), 
                             function(K) which.max(sapply(1:length(energy), 
                                                          function(x) sum(energy_ordered[[x]][1:K,2])
                                                          )
                                                   ))),
                      ncol=2, dimnames=list(NULL, c("GivenK", "OptimalBasis_L")))

  # And retained fts
    retained_fts <- lapply(1:length(energy_ordered),
                            function(x) energy_ordered[[optimal_L[x,2]]][optimal_L[1:x,1], 1]) # then the retained features of the basis that represent the K highest energy score columns

  return(list(basis_mats=tt_results$basis,
              optimal_params=optimal_L,
              retained_fts=retained_fts))
}
```



## Cross-Validation Data Split  

Splitting the data into a cross-validation set (80%) and hold-out test set (20%). Within the 80% cross-validation set, I then create a new variable identifying the five folds to be used in the cross-validation process. 

The length of stay and mortality models use the same cohort (the same inclusion criteria), so the same data splits are used for both of these analyses Our readmission cohort is limited only to patients who were readmitted or who survived out to one year withour readmission, so the data split is conduced separately for this subset of patients

### Mortality & Length of Stay 

```{r}
set.seed(2824)

hold_out_pts <- sample(1:nrow(cohort_full), size=nrow(cohort_full)/5, replace = F)

holdout_test <- cohort_full[hold_out_pts,]
# nrow(holdout_test)

cv_data <- cohort_full[setdiff(1:nrow(cohort_full), hold_out_pts),]
# nrow(cv_data)

(nrow(holdout_test) + nrow(cv_data)) == nrow(cohort_full)

cv_data$fold <- sample(c(rep(1, ceiling(nrow(cv_data)/5)),
                         rep(2, ceiling(nrow(cv_data)/5)),
                         rep(3, ceiling(nrow(cv_data)/5)),
                         rep(4, ceiling(nrow(cv_data)/5)),
                         rep(5, ceiling(nrow(cv_data)/5))
                         ),
                       size=nrow(cv_data), replace=F
                       )

table(cv_data$fold)
cat("\n")
cat("Printing frequency of \"Self-Pay\" insurane category across CV folds...\n")
count <- cv_data %>% filter(INSURANCE=="Self Pay") %>% count()
cat(paste0("Full analytic data (n=", nrow(cv_data), "): " ,  count, " (", round(100*count/nrow(cv_data), 2) ,"%)\n"))

for(i in 1:max(cv_data$fold)){
  count <- cv_data %>% filter(fold==i) %>% filter(INSURANCE=="Self Pay") %>% count()
  cat(paste0("Fold ", i, ": ", count, " (", round(100*count/nrow(cv_data %>% filter(fold==i)), 2) ,"%)\n"))
}
```

### Hospital Readmission 


```{r}
set.seed(70221)

cohort_readmit <- cohort_full %>% filter(!is.na(Yr1Readmit))

hold_out_readmit <- sample(1:nrow(cohort_readmit), size=nrow(cohort_readmit)/5, replace = F)

holdout_test_readmit <- cohort_readmit[hold_out_readmit,]
# nrow(holdout_test)

cv_data_readmit <- cohort_readmit[setdiff(1:nrow(cohort_readmit), hold_out_readmit),]
# nrow(cv_data)

(nrow(holdout_test_readmit) + nrow(cv_data_readmit)) == nrow(cohort_readmit)

cv_data_readmit$fold <- sample(c(rep(1, ceiling(nrow(cv_data_readmit)/5)),
                         rep(2, ceiling(nrow(cv_data_readmit)/5)),
                         rep(3, ceiling(nrow(cv_data_readmit)/5)),
                         rep(4, ceiling(nrow(cv_data_readmit)/5)),
                         rep(5, ceiling(nrow(cv_data_readmit)/5))
                         ),
                       size=nrow(cv_data_readmit), replace=F
                       )

table(cv_data_readmit$fold)

cat("\n")
cat("Printing frequency of \"Self-Pay\" insurane category across CV folds...\n")
count <- cv_data_readmit %>% filter(INSURANCE=="Self Pay") %>% count()
cat(paste0("Full analytic data (n=", nrow(cv_data_readmit), "): " ,  count, " (", round(100*count/nrow(cv_data_readmit), 2) ,"%)\n"))

for(i in 1:max(cv_data_readmit$fold)){
  count <- cv_data_readmit %>% filter(fold==i) %>% filter(INSURANCE=="Self Pay") %>% count()
  cat(paste0("Fold ", i, ": ", count, " (", round(100*count/nrow(cv_data_readmit %>% filter(fold==i)), 2) ,"%)\n"))
}
```


## Treelet Cross-Valdiation and Results Export

For each of our outcomes, similar processes are followed, which include:

1) Fitting the treelet model, using the previously defined `treelet_process` function, for each training fold
2) Then for K=1,2,...p-1 in this identified treelet:   
     a) Fitting the appropriate regression model in the training data using the K dimensions and corresponding optimal Lth basis  
     b) Using this fit model to predict probability of outcome (or outcome, in the length of stay negative binomial model)   
     c) Assess test fit (Briers & AUC for mortality, readmission; MSE for length of stay)   
     d) Export a data frame that contains test error for each K parameter and fold, and the average test Brier Score and AUC (so 177 observations (for 1 to p-1 values of K), and 13 columns, a K value, test-fold specific Brier Score and AUC values, and the two averages)


*A procedural note, the three outcome specific processes below include the same `brier`, `auc`, and `performance_df` named objects, so that each chunk writes over the results of the previous, but each chunk exports the results in its final step.*  
  
  
### In-Hospital Mortality


```{r}

brier <- list(c(), c(), c(), c(), c())
auc <- list(c(), c(), c(), c(), c())


for (fold_no in 1:max(cv_data$fold)) {
  
  train_cv <- cv_data[cv_data$fold!=fold_no, ]
  test_cv <- cv_data[cv_data$fold==fold_no, ]
    
  train_xmat <- train_cv %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  train_cov <- cov(train_xmat)

  test_xmat <- test_cv %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  
  tt_fold <- treelet_process(x_mat = train_xmat, cov_mat = train_cov)
  
  for(K in 1:length(tt_fold$basis_mats)){
        # basis_l <- tt_fold$basis_mats[[K]][,tt_fold$retained_fts[[K]]]
        basis_no <- tt_fold$optimal_params[i,2]
        basis_l <- tt_fold$basis_mats[[basis_no]][,tt_fold$retained_fts[[K]]]
    
        k_mat <- train_xmat %*%  basis_l
        
        train_glm_df <- train_cv %>% select(InHospMortality, GENDER, Age, INSURANCE) %>% cbind(., k_mat)
        if(K==1) colnames(train_glm_df)[5] <- "`1`"     # Account for weirdness in column naming from cbind() when test_kmat has one column 
        # train_glm <- glm(train_cv$InHospMortality ~ train_cv$GENDER + train_cv$Age + as.factor(train_cv$INSURANCE) + train_cv$HospitalLOS + k_mat ,
        #                  family = "binomial")
        
        train_glm <- glm(InHospMortality ~ . , data=train_glm_df,
                         family = "binomial")
        
        test_kmat <- test_xmat %*% basis_l
        test_glm_df <- test_cv %>% select(InHospMortality, GENDER, Age, INSURANCE) %>% cbind(., test_kmat)
        if(K==1) colnames(test_glm_df)[5] <- "`1`"     # Account for weirdness in column naming from cbind() when test_kmat has one column
        
        phat <- predict(object = train_glm, newdata = test_glm_df, type="response") 
      
        brier[[fold_no]][K] <- sum((phat - test_cv$InHospMortality)^2) / nrow(test_cv)
        auc[[fold_no]][K] <- pROC::roc(test_cv$InHospMortality, phat)$auc
        
    }
}


performance_df <- data.frame(K=c(1:length(brier[[1]])), 
                             BS_F1 = brier[[1]],
                             BS_F2 = brier[[2]],
                             BS_F3 = brier[[3]],
                             BS_F4 = brier[[4]],
                             BS_F5 = brier[[5]],
                             AUC_F1 = auc[[1]],
                             AUC_F2 = auc[[2]],
                             AUC_F3 = auc[[3]],
                             AUC_F4 = auc[[4]],
                             AUC_F5 = auc[[5]]) 

performance_df2 <- performance_df %>% mutate(BS_TestAvg = 
                            rowMeans(select(performance_df, starts_with("BS"))),
                          AUC_TestAvg =
                            rowMeans(select(performance_df, starts_with("AUC"))))

write.csv(performance_df2, here("Results/MortalityModel_CVPerformance_NoLOS_NewKLCode.csv"), row.names = F)

```




### Hospital Readmission 

```{r}
brier <- list(c(), c(), c(), c(), c())
auc <- list(c(), c(), c(), c(), c())


for (fold_no in 1:max(cv_data_readmit$fold)) {
  
  train_cv <- cv_data_readmit[cv_data_readmit$fold!=fold_no, ]
  test_cv <- cv_data_readmit[cv_data_readmit$fold==fold_no, ] 
    
  train_xmat <- train_cv %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  train_cov <- cov(train_xmat)

  test_xmat <- test_cv %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  
  tt_fold <- treelet_process(x_mat = train_xmat, cov_mat = train_cov)
  
  for(K in 1:length(tt_fold$basis_mats)){
        # basis_l <- tt_fold$basis_mats[[K]][,tt_fold$retained_fts[[K]]]
        basis_no <- tt_fold$optimal_params[K,2]
        basis_l <- tt_fold$basis_mats[[basis_no]][,tt_fold$retained_fts[[K]]]

        k_mat <- train_xmat %*%  basis_l
        
        train_glm_df <- train_cv %>% select(Yr1Readmit, GENDER, Age, INSURANCE, HospitalLOS) %>% cbind(., k_mat)
        if(K==1) colnames(train_glm_df)[6] <- "`1`"     # Account for weirdness in column naming from cbind() when test_kmat has one column 
        # train_glm <- glm(train_cv$InHospMortality ~ train_cv$GENDER + train_cv$Age + as.factor(train_cv$INSURANCE) + train_cv$HospitalLOS + k_mat ,
        #                  family = "binomial")
        
        train_glm <- glm(Yr1Readmit ~ . , data=train_glm_df,
                         family = "binomial")
        
        test_kmat <- test_xmat %*% basis_l
        test_glm_df <- test_cv %>% select(Yr1Readmit, GENDER, Age, INSURANCE, HospitalLOS) %>% cbind(., test_kmat)
        if(K==1) colnames(test_glm_df)[6] <- "`1`"     # Account for weirdness in column naming from cbind() when test_kmat has one column
        
        phat <- predict(object = train_glm, newdata = test_glm_df, type="response") 
      
        brier[[fold_no]][K] <- sum((phat - test_cv$Yr1Readmit)^2) / nrow(test_cv)
        auc[[fold_no]][K] <- pROC::roc(test_cv$Yr1Readmit, phat)$auc
        
    }
}

performance_df_readmit <- data.frame(K=c(1:length(brier[[1]])), 
                             BS_F1 = brier[[1]],
                             BS_F2 = brier[[2]],
                             BS_F3 = brier[[3]],
                             BS_F4 = brier[[4]],
                             BS_F5 = brier[[5]],
                             AUC_F1 = auc[[1]],
                             AUC_F2 = auc[[2]],
                             AUC_F3 = auc[[3]],
                             AUC_F4 = auc[[4]],
                             AUC_F5 = auc[[5]]) 

performance_df2_readmit <- performance_df_readmit %>% mutate(BS_TestAvg = 
                            rowMeans(select(performance_df_readmit, starts_with("BS"))),
                          AUC_TestAvg =
                            rowMeans(select(performance_df_readmit, starts_with("AUC"))))


write.csv(performance_df2_readmit, here("Results/ReadmissionModel_CVPerformance_NewKLCode.csv"), row.names = F)


```


### Hospital Length of Stay 

Cross-validation data splits are the same as the mortality data 

```{r}

MSE <- list(c(), c(), c(), c(), c())

# fold_no = 5

for (fold_no in 1:max(cv_data$fold)) {
  
  train_cv <- cv_data[cv_data$fold!=fold_no, ]
  test_cv <- cv_data[cv_data$fold==fold_no, ]
    
  train_xmat <- train_cv %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  train_cov <- cov(train_xmat)

  test_xmat <- test_cv %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  
  tt_fold <- treelet_process(x_mat = train_xmat, cov_mat = train_cov)
  
  for(K in 1:length(tt_fold$basis_mats)){
        # basis_l <- tt_fold$basis_mats[[K]][,tt_fold$retained_fts[[K]]]
        basis_no <- tt_fold$optimal_params[i,2]
        basis_l <- tt_fold$basis_mats[[basis_no]][,tt_fold$retained_fts[[K]]]
        
        k_mat <- train_xmat %*%  basis_l
        
        train_glm_df <- train_cv %>% select(HospitalLOS, GENDER, Age, INSURANCE) %>% cbind(., k_mat)
        if(K==1) colnames(train_glm_df)[5] <- "`1`"     # Account for weirdness in column naming from cbind() when test_kmat has one column 
        # train_glm <- glm(train_cv$InHospMortality ~ train_cv$GENDER + train_cv$Age + as.factor(train_cv$INSURANCE) + train_cv$HospitalLOS + k_mat ,
        #                  family = "binomial")
        
        train_glm <- glm.nb(HospitalLOS ~ . , data=train_glm_df)
        
        test_kmat <- test_xmat %*% basis_l
        test_glm_df <- test_cv %>% select(HospitalLOS, GENDER, Age, INSURANCE) %>% cbind(., test_kmat)
        if(K==1) colnames(test_glm_df)[5] <- "`1`"     # Account for weirdness in column naming from cbind() when test_kmat has one column
        
        yhat <- predict(object = train_glm, newdata = test_glm_df, type="response") 
      
        MSE[[fold_no]][K] <- sum((yhat - test_cv$HospitalLOS)^2) / nrow(test_cv)
        
        
    }
}


nb_MSE_df <- data.frame(K=c(1:length(MSE[[1]])), 
                             MSE_F1 = MSE[[1]],
                             MSE_F2 = MSE[[2]],
                             MSE_F3 = MSE[[3]],
                             MSE_F4 = MSE[[4]],
                             MSE_F5 = MSE[[5]]) 

nb_MSE_df2 <- nb_MSE_df %>% mutate(MSE_TestAvg = 
                            rowMeans(select(nb_MSE_df, starts_with("MSE"))))

write.csv(nb_MSE_df2, here("Results/LOSModel_MSE_DF_newKLCode.csv"), row.names = F)

```


## Tables & Figures

Having fit the treelet models above, we can now explore the results of the cross-validation processes. Each outcome section below includes chunks that:

1) Plot the cross-validation error for each K parameter (`Cross-Validation Figures`) and identify the K and L|K parameter 
2) Export the cluster membership and loadings  
3) Build the final model on the full cross-validation set and assess test fit, including object-specific figures to be included in thesis manuscript

### Mortality

```{r}
mortality_performance <- read.csv(here("Results/Treelet_KLOpt_WithinCVLoop/MortalityModel_CVPerformance_NoLOS_NewKLCode.csv"))

k_1sd <- mortality_performance[mortality_performance$BS_TestAvg<=(min(mortality_performance$BS_TestAvg) + sd(mortality_performance$BS_TestAvg)), ] %>% .[1,1]

mortality_performance <- mortality_performance %>% mutate(ParamFlag = 
                                   case_when(
                                     BS_TestAvg==min(BS_TestAvg) ~ "Minimizes Briers Score",
                                     K==k_1sd ~ "More Sparse Parameter",
                                     TRUE ~ NA_character_
                                   )) %>% ungroup()

```

#### Cross-Validation Figures

```{r}
ggplot(mortality_performance, aes(x=K, y=BS_TestAvg, color = as.factor(ParamFlag))) +
  geom_line(lwd=1.1, alpha=0.6) + geom_point(size=2.5) +
  theme_minimal() + ggtitle("In-Hospital Mortality Model") + 
  xlab("Value of Parameter K") + ylab("Average Briers Score (Across 5 Test Folds)") + 
  gghighlight(ParamFlag!=0) + labs(color="Optimal Parameters") +
  scale_color_brewer(type = "qual", palette = 6) + 
  theme(legend.position=c(0.75, 0.75), text = element_text(size=13.5))

# which.min(mortality_performance$BS_TestAvg)
# 
# # AUC Graph if of any interest 
# ggplot(mortality_performance, aes(x=K, y=AUC_TestAvg)) +
#   geom_line(lwd=1.1, alpha=0.6) + geom_point(size=2.5) +
#   theme_minimal() + ggtitle("In-Hospital Mortality Model") +
#   xlab("Value of Parameter K") + ylab("Average AUC (Across 5 Test Folds)")

```

#### Cluster Membership/Loading Export

```{r}
# Subsetting the highlighted K parameters above
  mortality_performance[!is.na(mortality_performance$ParamFlag),] 

# Refitting the treelet process in our training data to pull optimal L's for our highlighted K's
  cv_xmat <- cv_data  %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
  cv_cov <- cov(cv_xmat)

  tt_fnc_mortality <- treelet_process(cv_xmat, cv_cov)

  tt_fnc_mortality$optimal_params[c(123, 174),]
  tt_fnc_mortality$retained_fts[[123]]
  
  # For our 1-standard deviation parameter, pulling K-features from the Lth basis matrix
  final_basis_mortality <- tt_fnc_mortality$basis_mats[[57]][,tt_fnc_mortality$retained_fts[[123]]] %>%
    as.data.frame() %>% 
    mutate(LabelIndex = row_number(),
           RowMissCount = rowSums(.==0)) %>%
    filter(RowMissCount<123)

  labels_df <- cv_cov %>% colnames() %>%
    data.frame(code = ., label=1:ncol(cv_cov))

  loading_mat_mortality <- merge(final_basis_mortality, labels_df,
                                 all.x=T, by.y="label", by.x="LabelIndex")

  
  holder <- sapply(2:(ncol(loading_mat_mortality)-2), function(x) matrix(c(loading_mat_mortality[loading_mat_mortality[,x]!=0, "code"],
                                                                         loading_mat_mortality[loading_mat_mortality[,x]!=0, x]), 
                                                                         ncol=2))  
  
  # Lazily using a for loop to transform to an exportable csv
  i = 1
  reformat_loadingmat <- as.data.frame(holder[[i]]) %>% mutate(Feature=case_when(row_number()==1 ~ paste("Cluster", i),
                                                                                 TRUE ~ NA_character_)) %>% select(Feature, Code=V1, Loading=V2)
  
  for (i in 2:length(holder)){
  reformat_loadingmat <- rbind(reformat_loadingmat, 
                               as.data.frame(holder[[i]]) %>% mutate(Feature=case_when(row_number()==1 ~ paste("Cluster", i),
                                                                                 TRUE ~ NA_character_)) %>% select(Feature, Code=V1, Loading=V2))
  }
  
  
  write.csv(loading_mat_mortality,
            here("Results/LoadingMatrix_Mortality.csv"))
  
  # Pulling in labels for the full matrix
  reformat_loadingmat_labs <- reformat_loadingmat %>% mutate(Order=row_number()) %>%  
    merge(diagnosis_labs %>% select(ICD9_CODE, SHORT_TITLE), by.x="Code", by.y="ICD9_CODE", all.x=T) %>% arrange(Order) %>% select(-Order)
  
  write.csv(reformat_loadingmat_labs,
            here("Results/LoadingMatrix_Mortality_Redux.csv"), na = "")
  

  
```



#### Building Final Model and Assessting Test Fit

Using 1-Standard Deviation Parameter, building the logistic regression model on our the 80% cross-validation subset 

```{r}
final_basis <- tt_fnc_mortality$basis_mats[[57]][,tt_fnc_mortality$retained_fts[[123]]]

cv_xmat_transform <- cv_xmat %*% final_basis

cv_predictors <- cv_data %>% select(GENDER, Age, INSURANCE, InHospMortality) %>% cbind(., cv_xmat_transform) %>% as.data.frame()

dim(cv_predictors)

train_glm <- glm(InHospMortality ~ . , data=cv_predictors, family = "binomial")
train_glm %>% summary()
# confint(train_glm, parm = 1:7)

test_xmat <- holdout_test  %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
test_xmat_transform <- test_xmat %*% final_basis
test_predictors <- holdout_test %>% select(GENDER, Age, INSURANCE, InHospMortality) %>% cbind(., test_xmat_transform) %>% as.data.frame()

phat <- predict(object = train_glm, newdata = test_predictors, type="response") 
      
brier_test <- sum((phat - test_predictors$InHospMortality)^2) / nrow(holdout_test)
auc_test <- pROC::roc(test_predictors$InHospMortality, phat)$auc

# Exporting full model estimates 
ci95s <- confint.default(train_glm) # Using Wald approximation for confidence intervals, profile likelihood using confint() from MASS takes minutes to run (when it isn't crashing my R session) 

cbind(train_glm %>% summary() %>% .$coefficients %>% as.data.frame() %>% select(Estimate) %>% round(2),
      CI=paste0("[", (ci95s %>% round(2))[,1], ", ", (ci95s %>% round(2))[,2], "]"),
      train_glm %>% summary() %>% .$coefficients %>% as.data.frame() %>% select(`Pr(>|z|)`) %>% round(4)) %>% write.table("clipboard")
```

##### Graphing P-values/Coefficients

```{r}
# Height = -log(PValue); Color=Coefficient
train_glm %>% summary() %>% .$coefficients %>% as.data.frame() %>% mutate(Covariate=rownames(.), Order=row_number()) %>% select(PValue=`Pr(>|z|)`, everything()) %>% 
  filter(stringr::str_detect(Covariate, "[0-9]")) %>% arrange(desc(Estimate)) %>% mutate(Label = case_when(row_number()<=5 ~ str_replace_all(Covariate, "`", ""),
                                                                                                           TRUE ~ "")) %>% arrange(Order) %>%
  ggplot(aes(x=reorder(Covariate, Order), y=-log(PValue), fill=Estimate)) +
    geom_bar(stat="identity") + theme_minimal() +
  geom_text(aes(label=Label, group=Label),
            hjust=-0.45, vjust=0.95) +
  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title.x = element_text(size=16),
        axis.title.y = element_text(size=16),
        legend.title = element_text(size=12.4),
        legend.text =  element_text(size=10),
        legend.position = c(0.9, 0.65)) + 
  labs(caption="Inset text notes feature numbers of five highest coefficients") +
  xlab ("Treelet Feature") + ylab("-log(P-Value)") +
  scale_fill_continuous(type="viridis", name="Coefficient") 

```


##### Graphing Phat Distributions

```{r}
phat_df <- as.data.frame(cbind("EventProb" = phat, "ObsOut"=test_predictors$InHospMortality))

phat_df %>% ggplot(aes(x=EventProb, fill=as.factor(ObsOut))) +
  geom_density(alpha=0.3) + theme_minimal() +
  theme(legend.position=c(0.7, 0.6), text=element_text(size=13.5)) +
  ylab("Density") + xlab("Predicted Probability of In-Hospital Mortality")  + 
  scale_fill_manual(name="Observed Outcome", 
                      labels=c("No Mortality", "Mortality Event"),
                      values=c("lightblue", "violetred4")) +
  ggtitle("Density Curve of Predicted Probabilities of In-Hospital Mortality")


```


##### Comparative Models 

```{r}
# Logistic Regression of Retained Codes, no Basis Loading Scores
retained_codes <- loading_mat_mortality$code %>% unique()
length(retained_codes)

retain_traindf <- cv_data %>% select(GENDER, Age, INSURANCE, InHospMortality, !!retained_codes)

retain_train_glm <- glm(InHospMortality ~ . , data=retain_traindf, family = "binomial")

retain_test_df <- holdout_test %>% select(GENDER, Age, INSURANCE, InHospMortality, !!retained_codes)

retain_phat <- predict(object = retain_train_glm, newdata = retain_test_df, type="response") 
      
sum((retain_phat - retain_test_df$InHospMortality)^2) / nrow(retain_test_df)
  pROC::roc(retain_test_df$InHospMortality, retain_phat)$auc


# Logistic Regression of All Codes
all_traindf <- cv_data %>% select(GENDER, Age, INSURANCE, InHospMortality, matches("[0-9]$"))

all_train_glm <- glm(InHospMortality ~ . , data=all_traindf, family = "binomial")

all_test_df <- holdout_test %>% select(GENDER, Age, INSURANCE, InHospMortality, matches("[0-9]$"))

all_phat <- predict(object = all_train_glm, newdata = all_test_df, type="response") 
      
sum((all_phat - all_test_df$InHospMortality)^2) / nrow(retain_test_df)
pROC::roc(all_test_df$InHospMortality, all_phat)$auc

```




### Readmission

#### Figures of Model Validation


```{r}
readmit_performance <- read.csv(here("Results/Treelet_KLOpt_WithinCVLoop/ReadmissionModel_CVPerformance_NewKLCode.csv"))
# readmit_performance <- performance_df2_readmit
readmit_performance <- readmit_performance %>% mutate(BS_TestAvg = 
                            rowMeans(select(readmit_performance, starts_with("BS_F"))),
                          AUC_TestAvg =
                            rowMeans(select(readmit_performance, starts_with("AUC_F"))))

k_1sd_readmit <- readmit_performance[readmit_performance$BS_TestAvg<=(min(readmit_performance$BS_TestAvg) + sd(readmit_performance$BS_TestAvg)), ] %>% .[1,1]

readmit_performance <- readmit_performance %>% mutate(ParamFlag = 
                                   case_when(
                                     BS_TestAvg==min(BS_TestAvg) ~ "Minimizes Briers Score",
                                     K==k_1sd_readmit ~ "More Sparse Parameter",
                                     TRUE ~ NA_character_
                                   )) %>% ungroup()

ggplot(readmit_performance, aes(x=K, y=BS_TestAvg, color=as.factor(ParamFlag))) +
  geom_line(lwd=1.1, alpha=0.6) + geom_point(size=2.5) +
  theme_minimal() + ggtitle("Hospital Readmission Model") + 
  xlab("Value of Parameter K") + ylab("Average Briers Score (Across 5 Test Folds)") + 
  gghighlight(ParamFlag!=0) + labs(color="Optimal Parameters") +
  scale_color_brewer(type = "qual", palette = 6) + 
  theme(legend.position=c(0.65, 0.75), text = element_text(size=13.5))

# AUC CV Plot if of any interest later
# ggplot(readmit_performance, aes(x=K, y=AUC_TestAvg)) +
#   geom_line(lwd=1.1, alpha=0.6) + geom_point(size=2.5) +
#   theme_minimal() + ggtitle("Readmission Mortality Model") +
#   xlab("Value of Parameter K") + ylab("Average AUC (Across 5 Test Folds)")

```


#### Cluster Membership/Loading Export

```{r}
readmit_performance [!is.na(readmit_performance $ParamFlag),]

cv_readmit_xmat <- cv_data_readmit  %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
cv_readmit_cov <- cov(cv_readmit_xmat)

tt_fnc_readmit <- treelet_process(cv_readmit_xmat, cv_readmit_cov)

tt_fnc_readmit$optimal_params[c(readmit_performance [!is.na(readmit_performance $ParamFlag),] %>% pull(K)),]

# Matrix of loadings 
 # For our 1-standard deviation parameter, pulling K-features from the Lth basis matrix
  final_basis_readmit <- tt_fnc_readmit$basis_mats[[177]][,tt_fnc_readmit$retained_fts[[30]]] %>%
    as.data.frame() %>% 
    mutate(LabelIndex = row_number(),
           RowMissCount = rowSums(.==0)) %>%
    filter(RowMissCount<30)

  
  labels_df <- cv_readmit_cov %>% colnames() %>%
    data.frame(code = ., label=1:ncol(cv_readmit_cov))

  loading_mat_readmit <- merge(final_basis_readmit, labels_df,
                                 all.x=T, by.y="label", by.x="LabelIndex")

  
  holder <- sapply(2:(ncol(loading_mat_readmit)-2), function(x) matrix(c(loading_mat_readmit[loading_mat_readmit[,x]!=0, "code"],
                                                                         loading_mat_readmit[loading_mat_readmit[,x]!=0, x]), 
                                                                         ncol=2))  
  
  # Lazily using a for loop to transform to an exportable csv
  i = 1
  reformat_loadingmat_readmit <- as.data.frame(holder[[i]]) %>% mutate(Feature=case_when(row_number()==1 ~ paste("Cluster", i),
                                                                                 TRUE ~ NA_character_)) %>% select(Feature, Code=V1, Loading=V2)
  
  for (i in 2:length(holder)){
  reformat_loadingmat_readmit <- rbind(reformat_loadingmat_readmit, 
                               as.data.frame(holder[[i]]) %>% mutate(Feature=case_when(row_number()==1 ~ paste("Cluster", i),
                                                                                 TRUE ~ NA_character_)) %>% select(Feature, Code=V1, Loading=V2))
  }
  
  
  reformat_loadingmat_readmit_labs <- reformat_loadingmat_readmit %>% mutate(Order=row_number()) %>%  
    merge(diagnosis_labs %>% select(ICD9_CODE, SHORT_TITLE), by.x="Code", by.y="ICD9_CODE", all.x=T) %>% arrange(Order) %>% select(-Order)
  
  
  write.csv(loading_mat_readmit,
            here("Results/LoadingMatrix_Readmit.csv"))
  
  write.csv(reformat_loadingmat_readmit_labs,
            here("Results/LoadingMatrix_Readmit_Redux.csv"), na = "")
  

```



#### Building Final Model & Assessing Test Fit 
Using 1-Standard Deviation Parameter, building the logistic regression model on our the 80% cross-validation subset 

```{r}
final_basis_readmit <- tt_fnc_readmit$basis_mats[[177]][,tt_fnc_readmit$retained_fts[[30]]]

cv_xmat_transform_readmit <- cv_readmit_xmat %*% final_basis_readmit

cv_predictors_readmit <- cv_data_readmit %>% select(GENDER, Age, INSURANCE, Yr1Readmit) %>% cbind(., cv_xmat_transform_readmit) %>% as.data.frame()

train_glm_readmit <- glm(Yr1Readmit ~ . , data=cv_predictors_readmit, family = "binomial")
train_glm_readmit %>% summary()
confint(train_glm, parm = 1:7)


test_xmat_readmit <- holdout_test_readmit  %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
test_xmat_transform <- test_xmat_readmit %*% final_basis_readmit

test_predictors_readmit <- holdout_test_readmit %>% select(GENDER, Age, INSURANCE, Yr1Readmit) %>% cbind(., test_xmat_transform) %>% as.data.frame()

phat_readmit <- predict(object = train_glm_readmit, newdata = test_predictors_readmit, type="response") 
      
brier_test <- sum((phat_readmit - test_predictors_readmit$Yr1Readmit)^2) / nrow(test_predictors_readmit)
auc_test <- pROC::roc(test_predictors_readmit$Yr1Readmit, phat_readmit)$auc
brier_test
auc_test

# Exporting full model estimates 
ci95s_readmit <- confint.default(train_glm_readmit) # Using Wald approximation for confidence intervals, profile likelihood using confint() from MASS takes minutes to run (when it isn't crashing my R session) 

cbind(train_glm_readmit %>% summary() %>% .$coefficients %>% as.data.frame() %>% select(Estimate) %>% round(2),
      CI=paste0("[", (ci95s_readmit %>% round(2))[,1], ", ", (ci95s_readmit %>% round(2))[,2], "]"),
      train_glm_readmit %>% summary() %>% .$coefficients %>% as.data.frame() %>% select(`Pr(>|z|)`) %>% round(4)) %>% write.table("clipboard")
```

##### Graphing P-values/Coefficients
```{r}
train_glm_readmit %>% summary() %>% .$coefficients %>% as.data.frame() %>% mutate(Covariate=rownames(.), Order=row_number()) %>% select(PValue=`Pr(>|z|)`, everything()) %>% 
  filter(stringr::str_detect(Covariate, "[0-9]")) %>% arrange(desc(Estimate)) %>% mutate(Label = case_when(row_number()<=5 ~ str_replace_all(Covariate, "`", ""),
                                                                                                           TRUE ~ "")) %>% arrange(Order) %>%
  ggplot(aes(x=reorder(Covariate, Order), y=-log(PValue), fill=Estimate)) +
    geom_bar(stat="identity") + theme_minimal() +
  geom_text(aes(label=Label, group=Label),
            hjust=-0.9, vjust=0.95) +
  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title.x = element_text(size=16),
        axis.title.y = element_text(size=16),
        legend.title = element_text(size=12.4),
        legend.text =  element_text(size=10),
        legend.position = c(0.9, 0.65)) + 
  labs(caption="Inset text notes feature numbers of five highest coefficients") +
  xlab ("Treelet Feature") + ylab("-log(P-Value)") +
  scale_fill_continuous(type="viridis", name="Coefficient") 

```


##### Graphing Phat Distributions

```{r}
phat_readmit_df <- as.data.frame(cbind("EventProb" = phat_readmit, "ObsOut"=test_predictors_readmit$Yr1Readmit))

phat_readmit_df %>% ggplot(aes(x=EventProb, fill=as.factor(ObsOut))) +
  geom_density(alpha=0.3) + theme_minimal() +
  theme(legend.position=c(0.7, 0.6), text=element_text(size=13.5)) +
  ylab("Density") + xlab("Predicted Probability of Unplanned Hospital Readmission")  + 
  scale_fill_manual(name="Observed Outcome", 
                      labels=c("No Readmission", "Readmission"),
                      values=c("lightblue", "violetred4")) +
  ggtitle("Density Curve of Predicted Probabilities of Unplanned Hospital Readmission")


```


##### Comparative Models 

```{r}
# Logistic Regression of Retained Codes, no Basis Loading Scores
retained_codes_readmit <- loading_mat_readmit$code %>% unique()
length(retained_codes_readmit)

retain_traindf_readmit <- cv_data_readmit %>% select(GENDER, Age, INSURANCE, Yr1Readmit, !!retained_codes_readmit)

retain_train_glm_readmit <- glm(Yr1Readmit ~ . , data=retain_traindf_readmit, family = "binomial")

retain_test_df_readmit <- holdout_test_readmit %>% select(GENDER, Age, INSURANCE, Yr1Readmit, !!retained_codes_readmit)

retain_phat_readmit <- predict(object = retain_train_glm_readmit, newdata = retain_test_df_readmit, type="response") 
      
sum((retain_phat_readmit - retain_test_df_readmit$Yr1Readmit)^2) / length(retain_phat_readmit)
  pROC::roc(retain_test_df_readmit$Yr1Readmit, retain_phat_readmit)$auc


# Logistic Regression of All Codes
all_traindf_readmit <- cv_data_readmit %>% select(GENDER, Age, INSURANCE, Yr1Readmit, matches("[0-9]$"))

all_train_glm_readmit <- glm(Yr1Readmit ~ . , data=all_traindf_readmit, family = "binomial")

all_test_df_readmit <- holdout_test_readmit %>% select(GENDER, Age, INSURANCE, Yr1Readmit, matches("[0-9]$"))

all_phat_readmit <- predict(object = all_train_glm_readmit, newdata = all_test_df_readmit, type="response") 
      
sum((all_phat_readmit - all_test_df_readmit$Yr1Readmit)^2) / length(all_phat_readmit)
pROC::roc(all_test_df_readmit$Yr1Readmit, all_phat_readmit)$auc
```






### Length of Stay 




#### Figures of Model Validation

```{r}
los_performance <- read.csv(here("Results/Treelet_KLOpt_WithinCVLoop/LOSModel_MSE_DF_NewKLCode.csv"))
# los_performance <- read.csv(here("Results/Treelet_KKOpt_WithinCVLoop/LOSModel_MSE_DF.csv"))

k_1sd_los <- los_performance[los_performance$MSE_TestAvg<=(min(los_performance$MSE_TestAvg) + sd(los_performance$MSE_TestAvg)), ] %>% .[1,1]

los_performance <- los_performance %>% mutate(ParamFlag = 
                                   case_when(
                                     MSE_TestAvg==min(MSE_TestAvg) ~ "Minimizes MSE",
                                     K==k_1sd_los ~ "More Sparse Parameter",
                                     TRUE ~ NA_character_
                                   )) %>% ungroup()


ggplot(los_performance, aes(x=K, y=MSE_TestAvg, color = as.factor(ParamFlag))) +
  geom_line(lwd=1.1, alpha=0.6) + geom_point(size=2.5) +
  theme_minimal() + ggtitle("Hospital Length of Stay Model") + 
  xlab("Value of Parameter K") + ylab("Average Mean-Squared Error\n(Across 5 Test Folds)") + 
  gghighlight(ParamFlag!=0) + labs(color="Optimal Parameters") +
  scale_color_brewer(type = "qual", palette = 6) + 
  theme(legend.position=c(0.75, 0.75), text = element_text(size=13.5))

```

#### Cluster Membership/Loading Export

```{r}
los_performance [!is.na(los_performance $ParamFlag),]

cv_los_xmat <- cv_data  %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
cv_los_cov <- cov(cv_los_xmat)

tt_fnc_los <- treelet_process(cv_los_xmat, cv_los_cov)

tt_fnc_los$optimal_params[c(46, 115),]
tt_fnc_los$retained_fts[[46]]

# Matrix of loadings 
 # For our 1-standard deviation parameter, pulling K-features from the Lth basis matrix
  final_basis_los <- tt_fnc_los$basis_mats[[63]][,tt_fnc_los$retained_fts[[46]]] %>%
    as.data.frame() %>% 
    mutate(LabelIndex = row_number(),
           RowMissCount = rowSums(.==0)) %>%
    filter(RowMissCount<46)

  labels_df <- cv_los_cov %>% colnames() %>%
    data.frame(code = ., label=1:ncol(cv_los_cov))

  loading_mat_los <- merge(final_basis_los, labels_df,
                                 all.x=T, by.y="label", by.x="LabelIndex")

  
  holder <- sapply(2:(ncol(loading_mat_los)-2), function(x) matrix(c(loading_mat_los[loading_mat_los[,x]!=0, "code"],
                                                                     loading_mat_los[loading_mat_los[,x]!=0, x]),
                                                                   ncol=2))  
  
  # Lazily using a for loop to transform to an exportable csv
  i = 1
  reformat_loadingmat_los <- as.data.frame(holder[[i]]) %>% mutate(Feature=case_when(row_number()==1 ~ paste("Cluster", i),
                                                                                 TRUE ~ NA_character_)) %>% select(Feature, Code=V1, Loading=V2)
  
  for (i in 2:length(holder)){
  reformat_loadingmat_los <- rbind(reformat_loadingmat_los, 
                               as.data.frame(holder[[i]]) %>% mutate(Feature=case_when(row_number()==1 ~ paste("Cluster", i),
                                                                                 TRUE ~ NA_character_)) %>% select(Feature, Code=V1, Loading=V2))
  }
  
  reformat_loadingmat_los_labs <- reformat_loadingmat_los %>% mutate(Order=row_number()) %>%  
    merge(diagnosis_labs %>% select(ICD9_CODE, SHORT_TITLE), by.x="Code", by.y="ICD9_CODE", all.x=T) %>% arrange(Order) %>% select(-Order)
  
  length(unique(reformat_loadingmat_los$Code))
  
  write.csv(loading_mat_los,
            here("Results/LoadingMatrix_LOS.csv"))
  
  write.csv(reformat_loadingmat_los_labs,
            here("Results/LoadingMatrix_LOS_Redux.csv"), na = "")
  

```



#### Building Final Model and Assessting Test Fit

First fitting the Poisson model to assess overdispersion using the resulting deviance and $\chi^2$ distribution.

```{r}
poisson_los <- glm(HospitalLOS ~ . , data=cv_predictors, family="poisson")
poisson_los$deviance / poisson_los$df.residual # Values near 1 indicate evenly dispersed data (mean ~= variance), our value of 5.78 indicates overdispersion (variance ~=5.8*mean)

pchisq(poisson_los$deviance, df=poisson_los$df.residual, lower.tail = F)
  # Unsurprisingly significant

```

Now fitting the negative binomial model, again using the 1-Standard Deviation Parameter, on our the 80% cross-validation subset 

```{r}
final_basis <- tt_fnc_los$basis_mats[[63]][,tt_fnc_los$retained_fts[[46]]]

cv_xmat_transform <- cv_los_xmat %*% final_basis

cv_predictors <- cv_data %>% select(GENDER, Age, INSURANCE, HospitalLOS) %>% cbind(., cv_xmat_transform) %>% as.data.frame()

dim(cv_predictors)

train_glm_los <- glm.nb(HospitalLOS ~ . , data=cv_predictors)
train_glm_los %>% summary()
train_glm_los %>% str()

# confint(train_glm_los, parm = 1:7)

test_xmat <- holdout_test  %>% select(matches("0|1|2|4|5|6|9")) %>% select(-Yr1Readmit) %>% as.matrix()
test_xmat_transform <- test_xmat %*% final_basis
test_predictors <- holdout_test %>% select(GENDER, Age, INSURANCE, HospitalLOS) %>% cbind(., test_xmat_transform) %>% as.data.frame()

yhat <- predict(object = train_glm_los, newdata = test_predictors, type="response") 

(MSE <- sum((yhat - test_predictors$HospitalLOS)^2) / nrow(holdout_test)) %>% sqrt()

# Exporting full model estimates 
ci95s_los <- confint.default(train_glm_los) # Using Wald approximation for confidence intervals, profile likelihood using confint() from MASS takes minutes to run (when it isn't crashing my R session) 

cbind(train_glm_los %>% summary() %>% .$coefficients %>% as.data.frame() %>% select(Estimate) %>% round(2),
      CI=paste0("[", (ci95s_los %>% round(2))[,1], ", ", (ci95s_los %>% round(2))[,2], "]"),
      train_glm_los %>% summary() %>% .$coefficients %>% as.data.frame() %>% select(`Pr(>|z|)`) %>% round(4)) %>% write.table("clipboard")
```


##### Graphing P-Value/Coefficients
```{r}
train_glm_los %>% summary() %>% .$coefficients %>% as.data.frame() %>% mutate(Covariate=rownames(.), Order=row_number()) %>% select(PValue=`Pr(>|z|)`, everything()) %>% 
  filter(stringr::str_detect(Covariate, "[0-9]")) %>% arrange(desc(Estimate)) %>% mutate(Label = case_when(row_number()<=5 ~ str_replace_all(Covariate, "`", ""),
                                                                                                           TRUE ~ "")) %>% arrange(Order) %>%
  ggplot(aes(x=reorder(Covariate, Order), y=-log(PValue), fill=Estimate)) +
    geom_bar(stat="identity") + theme_minimal() +
  geom_text(aes(label=Label, group=Label),
            hjust=-0.35, vjust=0.95) +
  theme(axis.text.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.title.x = element_text(size=16),
        axis.title.y = element_text(size=16),
        legend.title = element_text(size=12.4),
        legend.text =  element_text(size=10),
        legend.position = c(0.9, 0.65)) + 
  labs(caption="Inset text notes feature numbers of five highest coefficients") +
  xlab ("Treelet Feature") + ylab("-log(P-Value)") +
  scale_fill_continuous(type="viridis", name="Coefficient") 
```

##### LOS Density Curve
```{r}
# Total Cohort
cohort_full %>% ggplot(aes(x=HospitalLOS)) +
  geom_density(lwd=1.3) + theme_minimal() + 
  xlab("Length of Stay (Days)") + ylab("Density") +
  xlim(c(0, 150)) +
  geom_text(label="Figure truncated at x=150 for legibility.\n n=12 patients with values >150 days not included in this visual", x=100, y=0.015) +
  NULL

(cohort_full %>% arrange(desc(HospitalLOS)) %>% filter(HospitalLOS>=150) %>% pull(HospitalLOS)) %>% length()

mean(cohort_full$HospitalLOS)
sd(cohort_full$HospitalLOS)

# # CV Training Cohort
# cv_data %>% ggplot(aes(x=HospitalLOS)) +
#   geom_density() + theme_minimal()
# 
# mean(cv_data$HospitalLOS)
# sd(cv_data$HospitalLOS)

```


##### Diagnositics

```{r}
# Poisson
los_poisson <- glm(HospitalLOS ~ ., data=cv_predictors, family="poisson")
los_poisson %>% summary()

# Negative Binomial # using cv_predictors, the resulting `los_nb` object is the same as the training glm fit earlier, simply renamed not to overwrite that object 
los_nb <- glm.nb(HospitalLOS ~ . , data=cv_predictors)
los_nb %>% summary()


1/train_glm_los$theta

llik_diff <- -2*(logLik(los_poisson) - logLik(los_nb))

pchisq(llik_diff, df=1, lower.tail = F)

summary(cohort_full$HospitalLOS)

pois_nb_comp <- data.frame(PoissonYhat = predict(object=los_poisson, newdata=test_predictors),
                           NegBinYhat = predict(object=los_nb, newdata=test_predictors))

pois_nb_comp %>% ggplot(aes(x=NegBinYhat, y=PoissonYhat)) +
  geom_point() + theme_minimal() + xlab("Negative Binomial Predictions") +
  ylab("Poisson Predictions")

```

##### Scatterplot of Observed vs Predictive

```{r}
yhat_df <- as.data.frame(cbind("PredictedLOS" = yhat, "ObservedLOS"=test_predictors$HospitalLOS))


# 
# inset <- yhat_df %>% ggplot(aes(x=ObservedLOS, y=PredictedLOS, color=as.factor(PredictedLOS>ObservedLOS))) +
#   geom_point(alpha=0.3) + theme_minimal() +
#   theme(legend.position="none", text=element_text(size=13.5)) + scale_color_manual(values=c("lightblue", "violetred4")) +
#   xlim(c(0, 100)) + ylim(c(0, 50)) + 
#   # ylab("Predicted Length of Stay") + xlab("Observed Length of Stay")  + 
#   # scale_color_manual(name="Prediction Error Direction", 
#   #                     labels=c("Predicted LOS > Observed LOS", "Predicted LOS < Observed LOS"),
#   #                     values=c("lightblue", "violetred4")) +
#   # ggtitle("Scatter Plot of Predicted and Observed Length of Stay Values")
#   NULL
# 
# 
# inset_tibble <- tibble(y=25, x=200,
#                        plot=list(inset))

yhat_df %>% ggplot(aes(x=ObservedLOS, y=PredictedLOS, color=as.factor(PredictedLOS>ObservedLOS))) +
  geom_point(alpha=0.3) + theme_minimal() +
  theme(legend.position=c(0.7, 0.6), text=element_text(size=13.5)) +
  ylab("Predicted Length of Stay") + xlab("Observed Length of Stay")  +
  scale_color_manual(name="Prediction Error Direction",
                      labels=c("Predicted LOS > Observed LOS", "Predicted LOS < Observed LOS"),
                      values=c("dodgerblue", "violetred4")) +
  ggtitle("Scatter Plot of Predicted and Observed Length of Stay Values") +
  # geom_text(x=125, y=30, label="Correlation of Predicted and\nObserved Length of Stay Values = 0.393") + 
  NULL 

```

##### Residuals and Number of Diagnoses

```{r}
num_diagnoses_df <- cbind(yhat_df,
                          NumDiagnoses = holdout_test %>% select(matches("^[0-9]")) %>% rowSums()) %>% 
                    mutate(Resid=PredictedLOS-ObservedLOS,
                           absResid = abs(PredictedLOS-ObservedLOS))

num_diagnoses_df %>% ggplot(aes(group=NumDiagnoses, y=Resid)) +
  geom_boxplot() + theme_minimal() + xlab("Number of ICD Diagnoses per Patient") +
  ylab("Predicted LOS - Observed LOS")

num_diagnoses_df %>% ggplot(aes(x=NumDiagnoses, y=absResid)) +
  geom_point() + theme_minimal() + xlab("Number of ICD Diagnoses per Patient") +
  ylab("|Predicted LOS - Observed LOS|")

num_diagnoses_df %>% ggplot(aes(x=ObservedLOS, y=Resid)) +
  geom_point() + theme_minimal() + xlab("Observed Length of Stay") +
  ylab("Predicted LOS - Observed LOS")

```




##### Distribution of Observed and Predicted LOS Values

```{r}
los_dens_df <- rbind(yhat_df %>% select(LOS=PredictedLOS) %>% mutate(Type="Predicted"),
                     yhat_df %>% select(LOS=ObservedLOS) %>% mutate(Type="Observed"))

los_dens_df %>% ggplot(aes(x=LOS, fill=as.factor(Type))) +
  geom_density(alpha=0.3) + theme_minimal() +
  theme(legend.position=c(0.7, 0.6), text=element_text(size=13.5)) +
  ylab("Density") + xlab("Length of Stay Value (Days)")  + 
  scale_fill_manual(name="Type of Data", 
                      labels=c("Observed", "Predicted"),
                      values=c("lightblue", "violetred4")) +
  ggtitle("Density Curve of Predicted & Observed Length of Stay Values") +
  xlim(c(0, 75))


```



##### Comparative Models 

```{r}
# Logistic Regression of Retained Codes, no Basis Loading Scores
retained_codes <- loading_mat_los$code %>% unique()
length(retained_codes)

retain_traindf <- cv_data %>% select(GENDER, Age, INSURANCE, InHospMortality, !!retained_codes)

retain_train_glm <- glm(InHospMortality ~ . , data=retain_traindf, family = "binomial")

retain_test_df <- holdout_test %>% select(GENDER, Age, INSURANCE, InHospMortality, !!retained_codes)

retain_phat <- predict(object = retain_train_glm, newdata = retain_test_df, type="response") 
      
sum((retain_phat - retain_test_df$InHospMortality)^2) / nrow(retain_test_df)
  pROC::roc(retain_test_df$InHospMortality, retain_phat)$auc


# Logistic Regression of All Codes
all_traindf <- cv_data %>% select(GENDER, Age, INSURANCE, InHospMortality, matches("[0-9]$"))

all_train_glm <- glm(InHospMortality ~ . , data=all_traindf, family = "binomial")

all_test_df <- holdout_test %>% select(GENDER, Age, INSURANCE, InHospMortality, matches("[0-9]$"))

all_phat <- predict(object = all_train_glm, newdata = all_test_df, type="response") 
      
sum((all_phat - all_test_df$InHospMortality)^2) / nrow(retain_test_df)
pROC::roc(all_test_df$InHospMortality, all_phat)$auc
```



## Appendix Analysis: Comparative Models


Exploratory analysis to see how the results of the treelet modelling above compares with the application of PCA, lasso, and possibly the use of the Charlson and/or Elixhauser comorbidity indexes as a predictor 



```{r}
require(caret)

cv5 <- trainControl(method="cv", 
                    number=5)

cv_data %>% head()
cv_data_readmit %>% head()
```


###  Mortality


#### LASSO

```{r}
lasso_mortality <-  train(as.factor(InHospMortality) ~ .,
                   data = cv_data %>% select(matches("^[0-9]"), InHospMortality, Age, GENDER, INSURANCE), 
                   method="glmnet",
                   metric="AUC",
                   trControl=cv5)


phat_lasso <- predict(object = lasso_mortality, newdata = holdout_test, type="prob")

((lasso_mortality$finalModel %>% coef(lasso_mortality$bestTune$lambda))[,1]!=0) %>% sum()
(lasso_mortality$finalModel %>% coef(lasso_mortality$bestTune$lambda))[,1] %>% .[.==0]
  # Uses 176 of 184 covariates (excludes 250.00, 780.39, 274.9, 714.0, 585.9, 441.2, 491.21, 785.0, and Private Insurance)

(lasso_auc_mortality <- pROC::auc(holdout_test$InHospMortality, phat_lasso[,1]) %>% round(4))

```


#### PCA
```{r}
pca_results <- prcomp(cv_data %>% select(matches("^[0-9]")), center = T, scale. = T)

(pca_mortality_df <- data.frame(PC = 1:178,
                         Var = pca_results$sdev^2) %>% 
              mutate(PropVar = Var / nrow(.),
                     CmltvPropVar = cumsum(PropVar)))


pca_mortality_df %>% ggplot(aes(x=PC, y=PropVar)) +
  geom_point(size=5, alpha=0.4) + geom_line(lwd=0.75) + theme_minimal() +
  ylab("Proportion of Variance Explained") + xlab("Principal Component") +
  ggtitle("Proportion of Variance Explained by Individual Principal Component")


pca_mortality_df %>% ggplot(aes(x=PC, y=CmltvPropVar)) +
  geom_point(size=5, alpha=0.4) + geom_line(lwd=0.75) + theme_minimal() +
  ylab("Cumulative Proportion of Variance Explained") + xlab("Principal Component") +
  ggtitle("Cumulative Proportion of Variance Explained by Principal Component")


n_retain <- 50

rotate_icd <- (cv_data %>% select(matches("^[0-9]")) %>% as.matrix())  %*%  pca_results$rotation[,1:n_retain]


pca_glm <- glm(InHospMortality ~ . ,
               data = cv_data %>% select(InHospMortality, Age, GENDER, INSURANCE) %>% cbind(., rotate_icd),
               family="binomial")   


test_rotate <- (holdout_test %>% select(matches("^[0-9]")) %>% as.matrix())  %*%  pca_results$rotation[,1:n_retain]
  
  
test_pcadf <- holdout_test %>% select(InHospMortality, Age, GENDER, INSURANCE) %>% cbind(., test_rotate)

test_pca_phat <- predict(newdata = test_pcadf, object=pca_glm, type="response")

(pca_auc_mortality <- pROC::auc(predict = test_pca_phat, response = holdout_test$InHospMortality) %>% round(4))
  
```


#### Charlson & Elixhauser

Re-importing ICD data (to include all Charlson & Elixhauser codes)

```{r}
all_diags <- read.csv(here("/Data/Raw/DIAGNOSES_ICD.csv"))

icd_train <- cv_data %>% select(SUBJECT_ID) %>% merge(., all_diags %>% select(SUBJECT_ID, ICD9_CODE), by="SUBJECT_ID")
icd_test <- holdout_test %>% select(SUBJECT_ID) %>% merge(., all_diags %>% select(SUBJECT_ID, ICD9_CODE), by="SUBJECT_ID")

# Using Charlson/Elixhauser group membership
  mortality_charlson_train <- icd_train %>% comorbid_charlson() %>% as.data.frame() %>% cbind(., cv_data %>% select(InHospMortality, Age, GENDER, INSURANCE))
  mortality_elix_train <- icd_train %>% comorbid_elix() %>% as.data.frame() %>% cbind(., cv_data %>% select(InHospMortality, Age, GENDER, INSURANCE))
  
  mortality_charlson_test <- icd_test %>% comorbid_charlson() %>% as.data.frame() %>% cbind(., holdout_test %>% select(InHospMortality, Age, GENDER, INSURANCE))
  mortality_elix_test <- icd_test %>% comorbid_elix() %>% as.data.frame() %>% cbind(., holdout_test %>% select(InHospMortality, Age, GENDER, INSURANCE))
  
  charlson_glm <- glm(InHospMortality ~ ., data=mortality_charlson_train, family = "binomial")
  elix_glm <- glm(InHospMortality ~ ., data=mortality_elix_train, family = "binomial")

  elix_phat <- predict(object = elix_glm, newdata = mortality_elix_test)
  elix_auc <- pROC::auc(predict = elix_phat, response=holdout_test$InHospMortality) %>% round(4)
  
  charlson_phat <- predict(object = charlson_glm, newdata = mortality_charlson_test)
  charlson_auc <- pROC::auc(predict = charlson_phat, response=holdout_test$InHospMortality)[1] %>% round(4)


# Using "score" (sum of group memberships, i.e. number of groups with a diagnosis)
  charlson_score_train <- icd_train %>% comorbid_charlson() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., cv_data %>% select(InHospMortality, Age, GENDER, INSURANCE))
  elix_score_train <- icd_train %>% comorbid_elix() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., cv_data %>% select(InHospMortality, Age, GENDER, INSURANCE))

  charlson_score_test <- icd_test %>% comorbid_charlson() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., holdout_test %>% select(InHospMortality, Age, GENDER, INSURANCE))
  elix_score_test <- icd_test %>% comorbid_elix() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., holdout_test %>% select(InHospMortality, Age, GENDER, INSURANCE))

  charlson_score_glm <- glm(InHospMortality ~ ., data=charlson_score_train, family = "binomial")
  elix_score_glm <- glm(InHospMortality ~ ., data=elix_score_train, family = "binomial")

  elix_score_phat <- predict(object = elix_score_glm, newdata = elix_score_test)
  elix_score_auc <- pROC::auc(predict = elix_score_phat, response=holdout_test$InHospMortality) %>% round(4)
  
  charlson_score_phat <- predict(object = charlson_score_glm, newdata = charlson_score_test)
  charlson_score_auc <- pROC::auc(predict = charlson_score_phat, response=holdout_test$InHospMortality)[1] %>% round(4)
```


```{r}
# Printout Results
cat("Elixhauser Categorical AUC: ", elix_auc, "\n")
cat("Charlson Categorical AUC: ", charlson_auc, "\n")
cat("Elixhauser Score AUC: ", elix_score_auc, "\n")
cat("Charlson Score AUC: ", charlson_score_auc, "\n")
cat("PCA AUC (retaining", n_retain, "PC's):", pca_auc_mortality, "\n")
cat("LASSO AUC:", lasso_auc_mortality, "\n")

```


### Readmission


#### LASSO

```{r}
glmnet_readmit <-  train(as.factor(Yr1Readmit) ~ .,
                   data = cv_data_readmit %>% select(matches("^[0-9]"), Yr1Readmit, Age, GENDER, INSURANCE), 
                   method="glmnet",
                   metric="AUC",
                   trControl=cv5)


phat_readmit <- predict(object = glmnet_readmit, newdata = holdout_test_readmit, type="prob")

(retained_fts_lasso <- ((glmnet_readmit$finalModel %>% coef(glmnet_readmit$bestTune$lambda))[,1]!=0) %>% sum())
  # Uses only 48 of 184 covariates (excludes 250.00, 780.39, 274.9, 714.0, 585.9, 441.2, 491.21, 785.0, and Private Insurance)

(lasso_auc_readmit <- pROC::auc(holdout_test_readmit$Yr1Readmit, phat_readmit[,1]) %>% round(4))
```

#### PCA

```{r}
pca_readmit <- prcomp(cv_data_readmit %>% select(matches("^[0-9]")), center = T, scale. = T)

(pca_readmit_df <- data.frame(PC = 1:178,
                         Var = pca_readmit$sdev^2) %>% 
              mutate(PropVar = Var / nrow(.),
                     CmltvPropVar = cumsum(PropVar)))


pca_readmit_df %>% ggplot(aes(x=PC, y=PropVar)) +
  geom_point(size=5, alpha=0.4) + geom_line(lwd=0.75) + theme_minimal() +
  ylab("Proportion of Variance Explained") + xlab("Principal Component") +
  ggtitle("Proportion of Variance Explained by Individual Principal Component")


pca_readmit_df %>% ggplot(aes(x=PC, y=CmltvPropVar)) +
  geom_point(size=5, alpha=0.4) + geom_line(lwd=0.75) + theme_minimal() +
  ylab("Cumulative Proportion of Variance Explained") + xlab("Principal Component") +
  ggtitle("Cumulative Proportion of Variance Explained by Principal Component")


n_retain <- 50

rotate_readmit <- (cv_data_readmit %>% select(matches("^[0-9]")) %>% as.matrix())  %*%  pca_readmit$rotation[,1:n_retain]


pca_readmit_glm <- glm(Yr1Readmit ~ . ,
               data = cv_data_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE) %>% cbind(., rotate_readmit),
               family="binomial")   


test_rotate_readmit <- (holdout_test_readmit %>% select(matches("^[0-9]")) %>% as.matrix())  %*%  pca_readmit$rotation[,1:n_retain]
  
test_pca_readmitdf <- holdout_test_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE) %>% cbind(., test_rotate_readmit)

test_pca_phat_readmit <- predict(newdata = test_pca_readmitdf, object=pca_readmit_glm, type="response")

(pca_auc_readmit <- pROC::auc(predict = test_pca_phat_readmit, response = holdout_test_readmit$Yr1Readmit) %>% round(4))
  
```


#### Charlson & Elixhauser
```{r}
all_diags <- read.csv(here("/Data/Raw/DIAGNOSES_ICD.csv"))

icd_train_readmit <- cv_data_readmit %>% select(SUBJECT_ID) %>% merge(., all_diags %>% select(SUBJECT_ID, ICD9_CODE), by="SUBJECT_ID")
icd_test_readmit <- holdout_test_readmit %>% select(SUBJECT_ID) %>% merge(., all_diags %>% select(SUBJECT_ID, ICD9_CODE), by="SUBJECT_ID")

# Using Charlson/Elixhauser group membership
  readmit_charlson_train <- icd_train_readmit %>% comorbid_charlson() %>% as.data.frame() %>% cbind(., cv_data_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))
  readmit_elix_train <- icd_train_readmit %>% comorbid_elix() %>% as.data.frame() %>% cbind(., cv_data_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))
  
  readmit_charlson_test <- icd_test_readmit %>% comorbid_charlson() %>% as.data.frame() %>% cbind(., holdout_test_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))
  readmit_elix_test <- icd_test_readmit %>% comorbid_elix() %>% as.data.frame() %>% cbind(., holdout_test_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))
  
  charlson_glm_readmit <- glm(Yr1Readmit ~ ., data=readmit_charlson_train, family = "binomial")
  elix_glm_readmit <- glm(Yr1Readmit ~ ., data=readmit_elix_train, family = "binomial")

  elix_phat_readmit <- predict(object = elix_glm_readmit, newdata = readmit_elix_test)
  elix_auc_readmit <- pROC::auc(predict = elix_phat_readmit, response=holdout_test_readmit$Yr1Readmit) %>% round(4)
  
  charlson_phat_readmit <- predict(object = charlson_glm_readmit, newdata = readmit_charlson_test)
  charlson_auc_readmit <- pROC::auc(predict = charlson_phat_readmit, response=holdout_test_readmit$Yr1Readmit)[1] %>% round(4)


# Using "score" (sum of group memberships, i.e. number of groups with a diagnosis)
  charlson_score_train_readmit <- icd_train_readmit %>% comorbid_charlson() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., cv_data_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))
  elix_score_train_readmit <- icd_train_readmit %>% comorbid_elix() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., cv_data_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))

  charlson_score_test_readmit <- icd_test_readmit %>% comorbid_charlson() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., holdout_test_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))
  elix_score_test_readmit <- icd_test_readmit %>% comorbid_elix() %>% as.data.frame() %>% mutate(score = rowSums(.)) %>% select(score) %>%  
                                             cbind(., holdout_test_readmit %>% select(Yr1Readmit, Age, GENDER, INSURANCE))

  charlson_score_glm_readmit <- glm(Yr1Readmit ~ ., data=charlson_score_train_readmit, family = "binomial")
  elix_score_glm_readmit <- glm(Yr1Readmit ~ ., data=elix_score_train_readmit, family = "binomial")

  elix_score_phat_readmit <- predict(object = elix_score_glm_readmit, newdata = elix_score_test_readmit)
  elix_score_auc_readmit <- pROC::auc(predict = elix_score_phat_readmit, response=holdout_test_readmit$Yr1Readmit) %>% round(4)
  
  charlson_score_phat_readmit <- predict(object = charlson_score_glm_readmit, newdata = charlson_score_test_readmit)
  charlson_score_auc_readmit <- pROC::auc(predict = charlson_score_phat_readmit, response=holdout_test_readmit$Yr1Readmit)[1] %>% round(4)
```



```{r}
  
# Printout Results
cat("Elixhauser Categorical AUC: ", elix_auc_readmit, "\n")
cat("Charlson Categorical AUC: ", charlson_auc_readmit, "\n")
cat("Elixhauser Score AUC: ", elix_score_auc_readmit, "\n")
cat("Charlson Score AUC: ", charlson_score_auc_readmit, "\n")
cat("PCA AUC (retaining ", n_retain, " components):", pca_auc_readmit, "\n")
cat("LASSO AUC (retaining", retained_fts_lasso, "features):", lasso_auc_readmit, "\n")
```

